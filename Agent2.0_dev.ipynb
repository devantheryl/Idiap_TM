{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime as datetime\n",
    "import gym\n",
    "from gym import envs\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam    \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random \n",
    "from collections import deque\n",
    "\n",
    "envs.registry.all()\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        #experience replay\n",
    "        self.memory = deque(maxlen = 20000)\n",
    "        \n",
    "        #discount rate\n",
    "        self.gamma = 0.95\n",
    "        \n",
    "        #epsilon-greedy params\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.epsilon_min = 0.1\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.target = self._build_model()\n",
    "        self.alighn_target_model()\n",
    "    \n",
    "    def set_test_mode(self,value,gamma = 0.95):\n",
    "    \n",
    "        if value:\n",
    "            self.gamma = 0\n",
    "        else:\n",
    "            self.gamma = gamma\n",
    "            \n",
    "    \n",
    "    def _build_model(self):\n",
    "          \n",
    "        model = Sequential()\n",
    "        \n",
    "        #hyper params to tune\n",
    "        model.add(Dense(64, input_dim = self.state_size, activation = 'relu'))\n",
    "        model.add(Dense(64, activation = 'relu'))\n",
    "        model.add(Dense(self.action_size, activation = 'linear'))\n",
    "        \n",
    "        model.compile(loss = 'mse', optimizer = Adam(learning_rate = self.learning_rate))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def alighn_target_model(self):\n",
    "        self.target.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def remember(self, state, action,reward,next_state,done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        #epsilon-greedy choice of the action to perform\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def replay(self, batch_size):  \n",
    "        \n",
    "        states = np.ndarray((0,4))\n",
    "        next_states = np.ndarray((0,4))\n",
    "        actions = []\n",
    "        rewards =[]\n",
    "        terminateds = []\n",
    "\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, terminated in minibatch:     \n",
    "            states = np.vstack((states, state))\n",
    "            next_states = np.vstack((next_states, next_state))\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            terminateds.append(terminated)\n",
    "        \n",
    "        pred_Q = self.model.predict(states) #predicted q-values\n",
    "        target_Q = self.target.predict(next_states)\n",
    "        \n",
    "        for i in range(len(pred_Q)):         \n",
    "            if terminateds[i]:\n",
    "                pred_Q[i,int(actions[i])] = rewards[i]\n",
    "            else:\n",
    "                pred_Q[i,int(actions[i])] = rewards[i] + self.gamma * np.amax(target_Q[i])\n",
    "                \n",
    "                \n",
    "        self.model.fit(states, pred_Q, epochs =1, verbose = 0)        \n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "        \n",
    "    def save(self, path):\n",
    "        self.model.save_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00315569  0.1818127   0.00341334 -0.33963457]]\n",
      "[[ 0.00679195 -0.01335765 -0.00337935 -0.04587721]]\n",
      "[[ 0.00652479 -0.20843098 -0.00429689  0.24573758]]\n",
      "[[ 0.00235617 -0.4034913   0.00061786  0.5370621 ]]\n",
      "[[-0.00571365 -0.20837803  0.0113591   0.2445739 ]]\n",
      "[[-0.00988121 -0.4036604   0.01625058  0.54081804]]\n",
      "[[-0.01795442 -0.20877057  0.02706694  0.25329936]]\n",
      "[[-0.02212983 -0.01404535  0.03213293 -0.03072477]]\n",
      "[[-0.02241074  0.18060142  0.03151843 -0.31309873]]\n",
      "[[-0.01879871 -0.01495503  0.02525646 -0.01064487]]\n",
      "[[-0.01909781 -0.21042992  0.02504356  0.28989854]]\n",
      "[[-0.02330641 -0.40589985  0.03084153  0.5903736 ]]\n",
      "[[-0.03142441 -0.6014398   0.042649    0.8926099 ]]\n",
      "[[-0.0434532  -0.40692145  0.0605012   0.61363274]]\n",
      "[[-0.05159163 -0.60283434  0.07277386  0.9247409 ]]\n",
      "[[-0.06364831 -0.7988598   0.09126867  1.2393775 ]]\n",
      "[[-0.07962551 -0.9950276   0.11605623  1.5592002 ]]\n",
      "[[-0.09952606 -0.8014704   0.14724022  1.3048615 ]]\n",
      "[[-0.11555547 -0.9981202   0.17333746  1.6397768 ]]\n",
      "[[-0.13551788 -0.8054017   0.206133    1.4057374 ]]\n",
      "[[-0.15162592 -1.0023984   0.23424774  1.7551516 ]]\n",
      "episode : 0/10, score : 21, e : 1.0\n",
      "score mean over 100 episode :  21.0\n",
      "[[ 0.03920542  0.17683561 -0.04885513 -0.28874743]]\n",
      "[[ 0.04274214  0.37261897 -0.05463007 -0.59642977]]\n",
      "[[ 0.05019452  0.5684612  -0.06655867 -0.90580803]]\n",
      "[[ 0.06156374  0.37430054 -0.08467483 -0.6347658 ]]\n",
      "[[ 0.06904975  0.18045537 -0.09737015 -0.36990443]]\n",
      "[[ 0.07265886  0.37681618 -0.10476823 -0.6916321 ]]\n",
      "[[ 0.08019518  0.5732237  -0.11860088 -1.0153736 ]]\n",
      "[[ 0.09165966  0.37986583 -0.13890834 -0.76216114]]\n",
      "[[ 0.09925697  0.18690272 -0.15415157 -0.51621234]]\n",
      "[[ 0.10299502  0.38382098 -0.16447581 -0.85322845]]\n",
      "[[ 0.11067145  0.58075684 -0.18154038 -1.1927837 ]]\n",
      "[[ 0.12228658  0.38838983 -0.20539606 -0.9620552 ]]\n",
      "[[ 0.13005438  0.5855909  -0.22463717 -1.3116019 ]]\n",
      "episode : 1/10, score : 13, e : 1.0\n",
      "score mean over 100 episode :  17.0\n",
      "[[ 0.03672678  0.20971856 -0.02385655 -0.2608574 ]]\n",
      "[[ 0.04092115  0.01494514 -0.0290737   0.02420644]]\n",
      "[[ 0.04122005  0.21047172 -0.02858957 -0.27750593]]\n",
      "[[ 0.04542949  0.40598962 -0.03413969 -0.5790671 ]]\n",
      "[[ 0.05354928  0.21136233 -0.04572103 -0.29733142]]\n",
      "[[ 0.05777653  0.01692095 -0.05166766 -0.01941145]]\n",
      "[[ 0.05811495 -0.17742342 -0.05205589  0.25653255]]\n",
      "[[ 0.05456648  0.0184016  -0.04692524 -0.05210461]]\n",
      "[[ 0.05493451  0.2141639  -0.04796733 -0.35921577]]\n",
      "[[ 0.05921778  0.40993375 -0.05515165 -0.6666298 ]]\n",
      "[[ 0.06741646  0.21562046 -0.06848424 -0.39180937]]\n",
      "[[ 0.07172887  0.4116441  -0.07632042 -0.70527416]]\n",
      "[[ 0.07996175  0.60773593 -0.09042591 -1.0209721 ]]\n",
      "[[ 0.09211647  0.41392756 -0.11084536 -0.7579963 ]]\n",
      "[[ 0.10039502  0.6103883  -0.12600528 -1.0834007 ]]\n",
      "[[ 0.11260279  0.4171338  -0.1476733  -0.83276486]]\n",
      "[[ 0.12094546  0.22430496 -0.16432859 -0.589928  ]]\n",
      "[[ 0.12543157  0.0318189  -0.17612715 -0.353184  ]]\n",
      "[[ 0.12606794 -0.16041853 -0.18319084 -0.12080292]]\n",
      "[[ 0.12285957  0.03679081 -0.1856069  -0.46522456]]\n",
      "[[ 0.12359539 -0.15529029 -0.19491138 -0.23630722]]\n",
      "[[ 0.12048958  0.04200463 -0.19963753 -0.5835877 ]]\n",
      "[[ 0.12132967  0.23928061 -0.21130928 -0.9319287 ]]\n",
      "episode : 2/10, score : 23, e : 0.99\n",
      "score mean over 100 episode :  19.0\n",
      "[[-0.03536311 -0.18891454  0.01404041  0.25011384]]\n",
      "[[-0.0391414   0.00600412  0.01904269 -0.0381076 ]]\n",
      "[[-0.03902132 -0.18938565  0.01828054  0.26052213]]\n",
      "[[-0.04280903 -0.38476372  0.02349098  0.5589145 ]]\n",
      "[[-0.0505043  -0.18997926  0.03466927  0.27372408]]\n",
      "[[-0.05430389 -0.38557827  0.04014375  0.57713705]]\n",
      "[[-0.06201546 -0.5812392   0.05168649  0.8821911 ]]\n",
      "[[-0.07364024 -0.7770237   0.06933031  1.1906646 ]]\n",
      "[[-0.08918072 -0.5828652   0.0931436   0.92049336]]\n",
      "[[-0.10083802 -0.7791141   0.11155347  1.2409354 ]]\n",
      "[[-0.1164203  -0.585587    0.13637218  0.9851778 ]]\n",
      "[[-0.12813205 -0.78224593  0.15607573  1.3173966 ]]\n",
      "[[-0.14377695 -0.58940387  0.18242367  1.0773498 ]]\n",
      "[[-0.15556504 -0.39709815  0.20397067  0.84701324]]\n",
      "[[-0.163507   -0.20525517  0.22091094  0.6247665 ]]\n",
      "episode : 3/10, score : 15, e : 0.98\n",
      "score mean over 100 episode :  18.0\n",
      "[[-0.02910637  0.16753322 -0.04889033 -0.2786715 ]]\n",
      "[[-0.02575571 -0.02685842 -0.05446376 -0.0018005 ]]\n",
      "[[-0.02629288 -0.22115868 -0.05449977  0.27321333]]\n",
      "[[-0.03071605 -0.41546237 -0.0490355   0.5482211 ]]\n",
      "[[-0.0390253  -0.21968709 -0.03807108  0.24050051]]\n",
      "[[-0.04341904 -0.02404255 -0.03326107 -0.06394384]]\n",
      "[[-0.04389989 -0.21867223 -0.03453995  0.21806225]]\n",
      "[[-0.04827334 -0.02307399 -0.0301787  -0.08531284]]\n",
      "[[-0.04873482  0.17246726 -0.03188496 -0.38736236]]\n",
      "[[-0.04528547  0.36802697 -0.0396322  -0.68992543]]\n",
      "[[-0.03792493  0.17347676 -0.05343071 -0.40997806]]\n",
      "[[-0.0344554   0.3693139  -0.06163028 -0.7190157 ]]\n",
      "[[-0.02706912  0.56523204 -0.07601059 -1.0304428 ]]\n",
      "[[-0.01576448  0.7612785  -0.09661945 -1.345989  ]]\n",
      "[[-5.38906490e-04  5.67495048e-01 -1.23539224e-01 -1.08503151e+00]]\n",
      "[[ 0.01081099  0.3742001  -0.14523986 -0.833527  ]]\n",
      "[[ 0.018295    0.57097614 -0.1619104  -1.168134  ]]\n",
      "[[ 0.02971452  0.7677909  -0.18527308 -1.5068889 ]]\n",
      "[[ 0.04507034  0.57533544 -0.21541086 -1.2773054 ]]\n",
      "episode : 4/10, score : 19, e : 0.97\n",
      "score mean over 100 episode :  18.2\n",
      "[[ 0.01475727 -0.18169287 -0.00310673  0.26460522]]\n",
      "[[ 0.01112341  0.01347329  0.00218538 -0.02905598]]\n",
      "[[ 0.01139287  0.20856383  0.00160426 -0.3210486 ]]\n",
      "[[ 0.01556415  0.4036629  -0.00481671 -0.61322516]]\n",
      "[[ 0.02363741  0.2086086  -0.01708122 -0.3220632 ]]\n",
      "[[ 0.02780958  0.40396956 -0.02352248 -0.6200836 ]]\n",
      "[[ 0.03588897  0.599412   -0.03592415 -0.9200811 ]]\n",
      "[[ 0.04787721  0.7950006  -0.05432577 -1.2238342 ]]\n",
      "[[ 0.06377722  0.99077857 -0.07880246 -1.5330317 ]]\n",
      "[[ 0.08359279  0.79668957 -0.10946309 -1.2659457 ]]\n",
      "[[ 0.09952658  0.6031232  -0.134782   -1.0094519 ]]\n",
      "[[ 0.11158905  0.7997614  -0.15497103 -1.34124   ]]\n",
      "[[ 0.12758428  0.9964567  -0.18179584 -1.6781266 ]]\n",
      "[[ 0.14751342  0.8038488  -0.21535838 -1.44713   ]]\n",
      "episode : 5/10, score : 14, e : 0.96\n",
      "score mean over 100 episode :  17.5\n",
      "[[-0.04549583 -0.24034533  0.04313399  0.26854235]]\n",
      "[[-0.05030273 -0.43605545  0.04850484  0.57451195]]\n",
      "[[-0.05902384 -0.63182265  0.05999508  0.8820722 ]]\n",
      "[[-0.0716603  -0.8277059   0.07763653  1.1929965 ]]\n",
      "[[-0.08821441 -0.6336706   0.10149645  0.92562246]]\n",
      "[[-0.10088783 -0.44005507  0.1200089   0.66648245]]\n",
      "[[-0.10968893 -0.24678855  0.13333856  0.41386575]]\n",
      "[[-0.1146247  -0.44352356  0.14161587  0.7454343 ]]\n",
      "[[-0.12349517 -0.6402861   0.15652455  1.0791196 ]]\n",
      "[[-0.13630089 -0.44753808  0.17810695  0.83936256]]\n",
      "[[-0.14525165 -0.25523666  0.1948942   0.6075605 ]]\n",
      "[[-0.15035638 -0.06329651  0.2070454   0.38203782]]\n",
      "[[-0.15162231  0.12837684  0.21468616  0.16110563]]\n",
      "episode : 6/10, score : 13, e : 0.95\n",
      "score mean over 100 episode :  16.857142857142858\n",
      "[[ 0.00654645  0.1673533  -0.02448948 -0.2538823 ]]\n",
      "[[ 0.00989352  0.3628162  -0.02956713 -0.55418795]]\n",
      "[[ 0.01714984  0.16812164 -0.04065089 -0.2709652 ]]\n",
      "[[ 0.02051227  0.3637994  -0.04607019 -0.5761874 ]]\n",
      "[[ 0.02778826  0.5595358  -0.05759394 -0.88302034]]\n",
      "[[ 0.03897898  0.36524135 -0.07525434 -0.6089851 ]]\n",
      "[[ 0.0462838   0.1712476  -0.08743405 -0.34092203]]\n",
      "[[ 0.04970876  0.3674977  -0.09425249 -0.6598456 ]]\n",
      "[[ 0.05705871  0.5637962  -0.1074494  -0.9806556 ]]\n",
      "[[ 0.06833463  0.37026563 -0.12706251 -0.7235633 ]]\n",
      "[[ 0.07573995  0.17710863 -0.14153378 -0.4734195 ]]\n",
      "[[ 0.07928212  0.373916   -0.15100217 -0.8071508 ]]\n",
      "[[ 0.08676044  0.5707492  -0.16714518 -1.143267  ]]\n",
      "[[ 0.09817542  0.37815788 -0.19001053 -0.90731823]]\n",
      "[[ 0.10573858  0.5752736  -0.20815688 -1.2531979 ]]\n",
      "[[ 0.11724405  0.77236277 -0.23322085 -1.6032071 ]]\n",
      "episode : 7/10, score : 16, e : 0.94\n",
      "score mean over 100 episode :  16.75\n",
      "[[-0.00381092 -0.17809302  0.04052322  0.30339104]]\n",
      "[[-0.00737278  0.01642868  0.04659104  0.02375858]]\n",
      "[[-0.00704421  0.21085258  0.04706621 -0.25386798]]\n",
      "[[-0.00282716  0.405272    0.04198885 -0.5313418 ]]\n",
      "[[ 0.00527828  0.20958537  0.03136202 -0.22572947]]\n",
      "[[0.00946999 0.01402956 0.02684743 0.07667891]]\n",
      "[[ 0.00975058 -0.18146677  0.028381    0.37770993]]\n",
      "[[ 0.00612125 -0.37698007  0.0359352   0.67920464]]\n",
      "[[-0.00141836 -0.18237524  0.0495193   0.39804855]]\n",
      "[[-0.00506586  0.01201049  0.05748027  0.12138011]]\n",
      "[[-0.00482565 -0.18388586  0.05990787  0.43162924]]\n",
      "[[-0.00850337  0.01033891  0.06854045  0.15841709]]\n",
      "[[-0.00829659  0.20441604  0.0717088  -0.11187994]]\n",
      "[[-0.00420827  0.00834372  0.0694712   0.202537  ]]\n",
      "[[-0.00404139  0.20240691  0.07352193 -0.06744751]]\n",
      "[[6.7434630e-06 6.3120923e-03 7.2172984e-02 2.4749607e-01]]\n",
      "[[ 1.3298531e-04 -1.8976243e-01  7.7122912e-02  5.6204259e-01]]\n",
      "[[-0.00366226  0.00419735  0.08836376  0.29461944]]\n",
      "[[-0.00357832  0.19795568  0.09425615  0.03106102]]\n",
      "[[0.0003808  0.0016173  0.09487737 0.35193163]]\n",
      "[[ 4.1314354e-04 -1.9471681e-01  1.0191600e-01  6.7296040e-01]]\n",
      "[[-0.00348119 -0.3910966   0.11537521  0.995913  ]]\n",
      "[[-0.01130312 -0.1976908   0.13529347  0.74157816]]\n",
      "[[-0.01525694 -0.00467014  0.15012504  0.49434802]]\n",
      "[[-0.01535034  0.18805122  0.16001199  0.2524886 ]]\n",
      "[[-0.01158932  0.38056964  0.16506177  0.01424305]]\n",
      "[[-0.00397793  0.18351255  0.16534662  0.35411924]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.0767455e-04  3.7594485e-01  1.7242901e-01  1.1779827e-01]]\n",
      "[[0.00721122 0.17882568 0.17478497 0.45953572]]\n",
      "[[0.01078774 0.37110206 0.1839757  0.22664094]]\n",
      "[[ 0.01820978  0.5631835   0.18850851 -0.00283461]]\n",
      "[[0.02947345 0.36592847 0.18845183 0.34290013]]\n",
      "[[0.03679202 0.16869536 0.19530982 0.6885894 ]]\n",
      "[[ 0.04016592 -0.02852364  0.2090816   1.0358502 ]]\n",
      "[[0.03959545 0.163299   0.22979861 0.81540567]]\n",
      "episode : 8/10, score : 35, e : 0.92\n",
      "score mean over 100 episode :  18.77777777777778\n",
      "[[ 0.00248547  0.20116608 -0.0180567  -0.3130764 ]]\n",
      "[[ 0.0065088   0.00630595 -0.02431823 -0.02614224]]\n",
      "[[ 0.00663491  0.20176806 -0.02484107 -0.32639754]]\n",
      "[[ 0.01067028  0.00700842 -0.03136902 -0.04165076]]\n",
      "[[ 0.01081044  0.20256583 -0.03220204 -0.34406355]]\n",
      "[[ 0.01486176  0.00791643 -0.03908331 -0.06170657]]\n",
      "[[ 0.01502009 -0.18662399 -0.04031744  0.21839365]]\n",
      "[[ 0.01128761  0.0090504  -0.03594957 -0.08672955]]\n",
      "[[ 0.01146862 -0.18553829 -0.03768416  0.19439802]]\n",
      "[[ 0.00775785 -0.3801015  -0.0337962   0.47495908]]\n",
      "[[ 1.5582131e-04 -1.8451899e-01 -2.4297018e-02  1.7181869e-01]]\n",
      "[[-0.00353456 -0.37928492 -0.02086064  0.4567387 ]]\n",
      "[[-0.01112026 -0.18387435 -0.01172587  0.15755405]]\n",
      "[[-0.01479774 -0.37882647 -0.00857479  0.44651482]]\n",
      "[[-2.2374274e-02 -5.7382607e-01  3.5550681e-04  7.3648250e-01]]\n",
      "[[-0.0338508  -0.37870905  0.01508516  0.44391146]]\n",
      "[[-0.04142497 -0.5740411   0.02396339  0.7413112 ]]\n",
      "[[-0.0529058  -0.37925807  0.03878961  0.456265  ]]\n",
      "[[-0.06049096 -0.57490635  0.04791491  0.76091796]]\n",
      "[[-0.07198909 -0.38047612  0.06313327  0.4836889 ]]\n",
      "[[-0.07959861 -0.5764296   0.07280704  0.7955824 ]]\n",
      "[[-0.0911272 -0.7724712  0.0887187  1.1102521]]\n",
      "[[-0.10657662 -0.5786197   0.11092374  0.84666765]]\n",
      "[[-0.11814902 -0.38517162  0.12785709  0.59082353]]\n",
      "[[-0.12585245 -0.5818299   0.13967356  0.92089075]]\n",
      "[[-0.13748905 -0.38884366  0.15809138  0.6751611 ]]\n",
      "[[-0.14526592 -0.19623068  0.1715946   0.43613008]]\n",
      "[[-0.14919053 -0.00390026  0.1803172   0.20207298]]\n",
      "[[-0.14926854 -0.20108134  0.18435866  0.54577565]]\n",
      "[[-0.15329017 -0.39824966  0.19527417  0.89041126]]\n",
      "[[-0.16125517 -0.59540826  0.2130824   1.2375749 ]]\n",
      "episode : 9/10, score : 31, e : 0.9\n",
      "score mean over 100 episode :  20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sort of main, to define as a class \"controller\"\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "batch_size = 32\n",
    "\n",
    "n_episode = 10\n",
    "UPDATE_FREQ = 16\n",
    "NETW_UPDATE_FREQ = 100\n",
    "loop_number = 0\n",
    "\n",
    "output_dir = 'model_output/cartepole'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "score_mean = deque(maxlen = 50)\n",
    "to_plot = []\n",
    "for e in range(n_episode):\n",
    "    \n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1,state_size])\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        score+=1\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1,state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        print(state)\n",
    "        if loop_number % UPDATE_FREQ == 0 and loop_number > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "            pass\n",
    "            \n",
    "        if loop_number % NETW_UPDATE_FREQ == 0:\n",
    "            \n",
    "            agent.alighn_target_model()\n",
    "            \n",
    "        loop_number += 1\n",
    "        if done:\n",
    "            print(\"episode : {}/{}, score : {}, e : {:.2}\".format(e, n_episode, score, agent.epsilon))\n",
    "            score_mean.append(score)\n",
    "            break\n",
    "        \n",
    "    if e%50 == 0:\n",
    "        #agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")\n",
    "        pass\n",
    "    print(\"score mean over 100 episode : \" ,np.mean(score_mean))\n",
    "    to_plot.append(np.mean(score_mean))\n",
    "    if (np.mean(score_mean) > 470):\n",
    "        print(\"trained after \", e, \" episodes\")\n",
    "        break\n",
    "plt.plot(to_plot)\n",
    "env.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.0\n",
      "88.0\n",
      "99.0\n",
      "111.0\n",
      "128.0\n",
      "154.0\n",
      "190.0\n",
      "206.0\n",
      "222.0\n",
      "240.0\n",
      "Mean evaluation return: 24.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for 100 episodes\n",
    "\n",
    "agent.set_test_mode(True)\n",
    "\n",
    "sum_rewards = 0.0\n",
    "nbr_episode = 10\n",
    "for _ in range(nbr_episode):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1,state_size])\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1,state_size])\n",
    "        sum_rewards += reward\n",
    "        \n",
    "        state = next_state\n",
    "    print(sum_rewards)\n",
    "print('Mean evaluation return:', sum_rewards / nbr_episode)\n",
    "\n",
    "# Close agent and environment\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]] \n",
      "\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]] \n",
      "\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]] \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-837331fbb4da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_Q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "state = np.array([[1,1,1,1]])\n",
    "env.close()\n",
    "\n",
    "states = np.ndarray((0,4))\n",
    "next_states = np.ndarray((0,4))\n",
    "pred_Q = np.ndarray((0,2))\n",
    "target_Q = np.ndarray((0,2))\n",
    "\n",
    "actions = np.ndarray((0,1))\n",
    "rewards = np.ndarray((0,1))\n",
    "\n",
    "states = np.vstack((states, state))\n",
    "states = np.vstack((states, state))\n",
    "states = np.vstack((states, state))\n",
    "\n",
    "next_states = np.vstack((next_states,state))\n",
    "next_states = np.vstack((next_states,state))\n",
    "next_states = np.vstack((next_states,state))\n",
    "\n",
    "actions = np.vstack((actions,np.array([[0]])))\n",
    "actions = np.vstack((actions,np.array([[1]])))\n",
    "actions = np.vstack((actions,np.array([[0]])))\n",
    "\n",
    "rewards = np.vstack((rewards,np.array([[1]])))\n",
    "rewards = np.vstack((rewards,np.array([[1]])))\n",
    "rewards = np.vstack((rewards,np.array([[1]])))\n",
    "\n",
    "pred_Q = np.vstack((pred_Q,np.array([[0.3,0.5]])))\n",
    "pred_Q = np.vstack((pred_Q,np.array([[0.3,0.5]])))\n",
    "pred_Q = np.vstack((pred_Q,np.array([[0.3,0.5]])))\n",
    "\n",
    "target_Q = np.vstack((target_Q,np.array([[0,2]])))\n",
    "target_Q = np.vstack((target_Q,np.array([[1,0]])))\n",
    "target_Q = np.vstack((target_Q,np.array([[1,3]])))\n",
    "\n",
    "\n",
    "print(states,\"\\n\")\n",
    "print(next_states,\"\\n\")\n",
    "print(actions,\"\\n\")\n",
    "print(rewards,\"\\n\")\n",
    "print(pred_Q[i,int(actions[i,0])])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(pred_Q)):\n",
    "    pred_Q[i,int(actions[i,0])] = rewards[i,0] + 0.9 * np.amax(target_Q[i])\n",
    "print(\"test : \\n\" ,pred_Q) \n",
    "\n",
    "\n",
    "nbrJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_job = 4\n",
    "nbr_operation = 3\n",
    "nbr_params = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "state_status = np.full((nbr_job,nbr_operation),0)\n",
    "state_proc_time = np.full((nbr_job,nbr_operation),1)\n",
    "state_exp_time = np.full((nbr_job,nbr_operation),2)\n",
    "state_exectuable = np.full((nbr_job,nbr_operation),3)\n",
    "\n",
    "state = np.stack([state_status,state_proc_time,state_exp_time,state_exectuable],axis = 2)\n",
    "\n",
    "print(state)\n",
    "print(state.shape)\n",
    "\n",
    "print(state[0,0,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
