{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime as datetime\n",
    "import gym\n",
    "from gym import envs\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam    \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import random \n",
    "from collections import deque\n",
    "\n",
    "envs.registry.all()\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "from wandb.keras import WandbCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        #experience replay\n",
    "        self.memory = deque(maxlen = 2000)\n",
    "        \n",
    "        #discount rate\n",
    "        self.gamma = 0.95\n",
    "        \n",
    "        #epsilon-greedy params\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.0001\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.target = self._build_model()\n",
    "        self.alighn_target_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \n",
    "        wandb.init(config = {\n",
    "            \"gamma\" : 0.95,\n",
    "            \"epsilon_decay\" : 0.995,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 30,\n",
    "            \"neuroneLayer1\" : 30,\n",
    "            \"neuroneLayer2\" : 24,\n",
    "            \"activation1\" : \"relu\",\n",
    "            \"activation2\" : \"relu\",\n",
    "            \"activation_out\" : \"linear\"\n",
    "        })\n",
    "        \n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        #hyper params to tune\n",
    "        model.add(Dense(30, input_dim = self.state_size, activation = 'relu'))\n",
    "        model.add(Dense(24, activation = 'relu'))\n",
    "        model.add(Dense(self.action_size, activation = 'linear'))\n",
    "        \n",
    "        model.compile(loss = 'mse', optimizer = Adam(lr = self.learning_rate))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def alighn_target_model(self):\n",
    "        self.target.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def remember(self, state, action,reward,next_state,done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        #epsilon-greedy choice of the action to perform\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def replay(self, batch_size):  \n",
    "    \n",
    "        x = np.ndarray((0,4))\n",
    "        y = np.ndarray((0,2))\n",
    "        \n",
    "        \n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, terminated in minibatch:\n",
    "            \n",
    "            target = self.model.predict(state)\n",
    "            \n",
    "            if terminated:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target.predict(next_state)\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "            \n",
    "            #x = np.vstack((x, state))\n",
    "            #y = np.vstack((y, target_f))\n",
    "        \n",
    "        \n",
    "        \n",
    "            self.model.fit(state, target, epochs =1, verbose = 0,\n",
    "            callbacks=[WandbCallback()])\n",
    "        \n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "        \n",
    "    def save(self, path):\n",
    "        self.model.save_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\LDE/.netrc\n",
      "wandb: Currently logged in as: devantheryl (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stellar-cherry-26</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/devantheryl/RL_PLAY\" target=\"_blank\">https://wandb.ai/devantheryl/RL_PLAY</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/devantheryl/RL_PLAY/runs/3anfshfb\" target=\"_blank\">https://wandb.ai/devantheryl/RL_PLAY/runs/3anfshfb</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145754-3anfshfb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3anfshfb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20028<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145754-3anfshfb\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145754-3anfshfb\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stellar-cherry-26</strong>: <a href=\"https://wandb.ai/devantheryl/RL_PLAY/runs/3anfshfb\" target=\"_blank\">https://wandb.ai/devantheryl/RL_PLAY/runs/3anfshfb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3anfshfb). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">scarlet-fire-32</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/devantheryl/uncategorized\" target=\"_blank\">https://wandb.ai/devantheryl/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/devantheryl/uncategorized/runs/1z5srq9p\" target=\"_blank\">https://wandb.ai/devantheryl/uncategorized/runs/1z5srq9p</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145759-1z5srq9p</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1z5srq9p) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2620<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145759-1z5srq9p\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145759-1z5srq9p\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">scarlet-fire-32</strong>: <a href=\"https://wandb.ai/devantheryl/uncategorized/runs/1z5srq9p\" target=\"_blank\">https://wandb.ai/devantheryl/uncategorized/runs/1z5srq9p</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1z5srq9p). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fragrant-water-33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/devantheryl/uncategorized\" target=\"_blank\">https://wandb.ai/devantheryl/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/devantheryl/uncategorized/runs/mho33gpa\" target=\"_blank\">https://wandb.ai/devantheryl/uncategorized/runs/mho33gpa</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\LDE\\Prog\\projet_master\\digital_twins\\wandb\\run-20211213_145809-mho33gpa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode : 0/1000, score : 19, e : 1.0\n",
      "episode : 1/1000, score : 28, e : 1.0\n",
      "episode : 2/1000, score : 14, e : 0.99\n",
      "episode : 3/1000, score : 16, e : 0.99\n",
      "episode : 4/1000, score : 27, e : 0.99\n",
      "episode : 5/1000, score : 33, e : 0.98\n",
      "episode : 6/1000, score : 17, e : 0.98\n",
      "episode : 7/1000, score : 14, e : 0.97\n",
      "episode : 8/1000, score : 23, e : 0.97\n",
      "episode : 9/1000, score : 24, e : 0.96\n",
      "episode : 10/1000, score : 11, e : 0.96\n",
      "episode : 11/1000, score : 33, e : 0.95\n",
      "episode : 12/1000, score : 20, e : 0.95\n",
      "episode : 13/1000, score : 24, e : 0.94\n",
      "episode : 14/1000, score : 21, e : 0.94\n",
      "episode : 15/1000, score : 15, e : 0.93\n",
      "episode : 16/1000, score : 30, e : 0.93\n",
      "episode : 17/1000, score : 15, e : 0.92\n",
      "episode : 18/1000, score : 29, e : 0.92\n",
      "episode : 19/1000, score : 13, e : 0.91\n",
      "episode : 20/1000, score : 24, e : 0.91\n",
      "episode : 21/1000, score : 11, e : 0.9\n",
      "episode : 22/1000, score : 11, e : 0.9\n",
      "episode : 23/1000, score : 11, e : 0.9\n",
      "episode : 24/1000, score : 24, e : 0.89\n",
      "episode : 25/1000, score : 14, e : 0.89\n",
      "episode : 26/1000, score : 10, e : 0.88\n",
      "episode : 27/1000, score : 12, e : 0.88\n",
      "episode : 28/1000, score : 25, e : 0.87\n",
      "episode : 29/1000, score : 37, e : 0.87\n",
      "episode : 30/1000, score : 17, e : 0.86\n",
      "episode : 31/1000, score : 31, e : 0.86\n",
      "episode : 32/1000, score : 14, e : 0.86\n",
      "episode : 33/1000, score : 15, e : 0.85\n",
      "episode : 34/1000, score : 23, e : 0.85\n",
      "episode : 35/1000, score : 35, e : 0.84\n",
      "episode : 36/1000, score : 15, e : 0.84\n",
      "episode : 37/1000, score : 20, e : 0.83\n",
      "episode : 38/1000, score : 17, e : 0.83\n",
      "episode : 39/1000, score : 15, e : 0.83\n",
      "episode : 40/1000, score : 20, e : 0.82\n",
      "episode : 41/1000, score : 9, e : 0.82\n",
      "episode : 42/1000, score : 11, e : 0.81\n",
      "episode : 43/1000, score : 14, e : 0.81\n",
      "episode : 44/1000, score : 21, e : 0.81\n",
      "episode : 45/1000, score : 15, e : 0.8\n",
      "episode : 46/1000, score : 13, e : 0.8\n",
      "episode : 47/1000, score : 11, e : 0.79\n",
      "episode : 48/1000, score : 20, e : 0.79\n",
      "episode : 49/1000, score : 78, e : 0.79\n",
      "episode : 50/1000, score : 13, e : 0.78\n",
      "episode : 51/1000, score : 10, e : 0.78\n",
      "episode : 52/1000, score : 21, e : 0.77\n",
      "episode : 53/1000, score : 38, e : 0.77\n",
      "episode : 54/1000, score : 9, e : 0.77\n",
      "episode : 55/1000, score : 20, e : 0.76\n",
      "episode : 56/1000, score : 13, e : 0.76\n",
      "episode : 57/1000, score : 13, e : 0.76\n",
      "episode : 58/1000, score : 10, e : 0.75\n",
      "episode : 59/1000, score : 11, e : 0.75\n",
      "episode : 60/1000, score : 17, e : 0.74\n",
      "episode : 61/1000, score : 19, e : 0.74\n",
      "episode : 62/1000, score : 17, e : 0.74\n",
      "episode : 63/1000, score : 26, e : 0.73\n",
      "episode : 64/1000, score : 25, e : 0.73\n",
      "episode : 65/1000, score : 13, e : 0.73\n",
      "episode : 66/1000, score : 10, e : 0.72\n",
      "episode : 67/1000, score : 14, e : 0.72\n",
      "episode : 68/1000, score : 10, e : 0.71\n",
      "episode : 69/1000, score : 20, e : 0.71\n",
      "episode : 70/1000, score : 13, e : 0.71\n",
      "episode : 71/1000, score : 12, e : 0.7\n",
      "episode : 72/1000, score : 10, e : 0.7\n",
      "episode : 73/1000, score : 27, e : 0.7\n",
      "episode : 74/1000, score : 26, e : 0.69\n",
      "episode : 75/1000, score : 10, e : 0.69\n",
      "episode : 76/1000, score : 17, e : 0.69\n",
      "episode : 77/1000, score : 20, e : 0.68\n",
      "episode : 78/1000, score : 31, e : 0.68\n",
      "episode : 79/1000, score : 15, e : 0.68\n",
      "episode : 80/1000, score : 15, e : 0.67\n",
      "episode : 81/1000, score : 15, e : 0.67\n",
      "episode : 82/1000, score : 19, e : 0.67\n",
      "episode : 83/1000, score : 11, e : 0.66\n",
      "episode : 84/1000, score : 17, e : 0.66\n",
      "episode : 85/1000, score : 16, e : 0.66\n",
      "episode : 86/1000, score : 14, e : 0.65\n",
      "episode : 87/1000, score : 13, e : 0.65\n",
      "episode : 88/1000, score : 11, e : 0.65\n",
      "episode : 89/1000, score : 13, e : 0.64\n",
      "episode : 90/1000, score : 23, e : 0.64\n",
      "episode : 91/1000, score : 15, e : 0.64\n",
      "episode : 92/1000, score : 19, e : 0.63\n",
      "episode : 93/1000, score : 17, e : 0.63\n",
      "episode : 94/1000, score : 19, e : 0.63\n",
      "episode : 95/1000, score : 13, e : 0.62\n",
      "episode : 96/1000, score : 18, e : 0.62\n",
      "episode : 97/1000, score : 16, e : 0.62\n",
      "episode : 98/1000, score : 21, e : 0.61\n",
      "episode : 99/1000, score : 19, e : 0.61\n",
      "episode : 100/1000, score : 11, e : 0.61\n",
      "episode : 101/1000, score : 32, e : 0.61\n",
      "episode : 102/1000, score : 22, e : 0.6\n",
      "episode : 103/1000, score : 13, e : 0.6\n",
      "episode : 104/1000, score : 44, e : 0.6\n",
      "episode : 105/1000, score : 22, e : 0.59\n",
      "episode : 106/1000, score : 17, e : 0.59\n",
      "episode : 107/1000, score : 17, e : 0.59\n",
      "episode : 108/1000, score : 16, e : 0.58\n",
      "episode : 109/1000, score : 22, e : 0.58\n",
      "episode : 110/1000, score : 30, e : 0.58\n",
      "episode : 111/1000, score : 37, e : 0.58\n",
      "episode : 112/1000, score : 11, e : 0.57\n",
      "episode : 113/1000, score : 9, e : 0.57\n",
      "episode : 114/1000, score : 11, e : 0.57\n",
      "episode : 115/1000, score : 10, e : 0.56\n",
      "episode : 116/1000, score : 20, e : 0.56\n",
      "episode : 117/1000, score : 19, e : 0.56\n",
      "episode : 118/1000, score : 38, e : 0.56\n",
      "episode : 119/1000, score : 60, e : 0.55\n",
      "episode : 120/1000, score : 35, e : 0.55\n",
      "episode : 121/1000, score : 13, e : 0.55\n",
      "episode : 122/1000, score : 23, e : 0.55\n",
      "episode : 123/1000, score : 40, e : 0.54\n",
      "episode : 124/1000, score : 27, e : 0.54\n",
      "episode : 125/1000, score : 17, e : 0.54\n",
      "episode : 126/1000, score : 29, e : 0.53\n",
      "episode : 127/1000, score : 13, e : 0.53\n",
      "episode : 128/1000, score : 18, e : 0.53\n",
      "episode : 129/1000, score : 18, e : 0.53\n",
      "episode : 130/1000, score : 42, e : 0.52\n",
      "episode : 131/1000, score : 22, e : 0.52\n",
      "episode : 132/1000, score : 34, e : 0.52\n",
      "episode : 133/1000, score : 66, e : 0.52\n",
      "episode : 134/1000, score : 62, e : 0.51\n",
      "episode : 135/1000, score : 37, e : 0.51\n",
      "episode : 136/1000, score : 65, e : 0.51\n",
      "episode : 137/1000, score : 51, e : 0.51\n",
      "episode : 138/1000, score : 77, e : 0.5\n",
      "episode : 139/1000, score : 26, e : 0.5\n",
      "episode : 140/1000, score : 14, e : 0.5\n",
      "episode : 141/1000, score : 12, e : 0.5\n",
      "episode : 142/1000, score : 18, e : 0.49\n",
      "episode : 143/1000, score : 12, e : 0.49\n",
      "episode : 144/1000, score : 51, e : 0.49\n",
      "episode : 145/1000, score : 47, e : 0.49\n",
      "episode : 146/1000, score : 50, e : 0.48\n",
      "episode : 147/1000, score : 93, e : 0.48\n",
      "episode : 148/1000, score : 57, e : 0.48\n",
      "episode : 149/1000, score : 79, e : 0.48\n",
      "episode : 150/1000, score : 74, e : 0.47\n",
      "episode : 151/1000, score : 37, e : 0.47\n",
      "episode : 152/1000, score : 26, e : 0.47\n",
      "episode : 153/1000, score : 200, e : 0.47\n",
      "episode : 154/1000, score : 38, e : 0.46\n",
      "episode : 155/1000, score : 20, e : 0.46\n",
      "episode : 156/1000, score : 40, e : 0.46\n",
      "episode : 157/1000, score : 103, e : 0.46\n",
      "episode : 158/1000, score : 18, e : 0.46\n",
      "episode : 159/1000, score : 31, e : 0.45\n",
      "episode : 160/1000, score : 66, e : 0.45\n",
      "episode : 161/1000, score : 36, e : 0.45\n",
      "episode : 162/1000, score : 60, e : 0.45\n",
      "episode : 163/1000, score : 55, e : 0.44\n",
      "episode : 164/1000, score : 30, e : 0.44\n",
      "episode : 165/1000, score : 35, e : 0.44\n",
      "episode : 166/1000, score : 36, e : 0.44\n",
      "episode : 167/1000, score : 34, e : 0.44\n",
      "episode : 168/1000, score : 44, e : 0.43\n",
      "episode : 169/1000, score : 87, e : 0.43\n",
      "episode : 170/1000, score : 47, e : 0.43\n",
      "episode : 171/1000, score : 40, e : 0.43\n",
      "episode : 172/1000, score : 45, e : 0.42\n",
      "episode : 173/1000, score : 53, e : 0.42\n",
      "episode : 174/1000, score : 38, e : 0.42\n",
      "episode : 175/1000, score : 58, e : 0.42\n",
      "episode : 176/1000, score : 90, e : 0.42\n",
      "episode : 177/1000, score : 56, e : 0.41\n",
      "episode : 178/1000, score : 52, e : 0.41\n",
      "episode : 179/1000, score : 158, e : 0.41\n",
      "episode : 180/1000, score : 138, e : 0.41\n",
      "episode : 181/1000, score : 81, e : 0.41\n",
      "episode : 182/1000, score : 41, e : 0.4\n",
      "episode : 183/1000, score : 24, e : 0.4\n",
      "episode : 184/1000, score : 54, e : 0.4\n",
      "episode : 185/1000, score : 54, e : 0.4\n",
      "episode : 186/1000, score : 82, e : 0.4\n",
      "episode : 187/1000, score : 48, e : 0.39\n",
      "episode : 188/1000, score : 105, e : 0.39\n",
      "episode : 189/1000, score : 85, e : 0.39\n",
      "episode : 190/1000, score : 64, e : 0.39\n",
      "episode : 191/1000, score : 43, e : 0.39\n",
      "episode : 192/1000, score : 77, e : 0.38\n",
      "episode : 193/1000, score : 35, e : 0.38\n",
      "episode : 194/1000, score : 46, e : 0.38\n",
      "episode : 195/1000, score : 37, e : 0.38\n",
      "episode : 196/1000, score : 59, e : 0.38\n",
      "episode : 197/1000, score : 87, e : 0.37\n",
      "episode : 198/1000, score : 68, e : 0.37\n",
      "episode : 199/1000, score : 87, e : 0.37\n",
      "episode : 200/1000, score : 50, e : 0.37\n",
      "episode : 201/1000, score : 56, e : 0.37\n",
      "episode : 202/1000, score : 84, e : 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode : 203/1000, score : 61, e : 0.36\n",
      "episode : 204/1000, score : 47, e : 0.36\n",
      "episode : 205/1000, score : 35, e : 0.36\n",
      "episode : 206/1000, score : 41, e : 0.36\n",
      "episode : 207/1000, score : 148, e : 0.36\n",
      "episode : 208/1000, score : 60, e : 0.35\n",
      "episode : 209/1000, score : 68, e : 0.35\n",
      "episode : 210/1000, score : 55, e : 0.35\n",
      "episode : 211/1000, score : 53, e : 0.35\n",
      "episode : 212/1000, score : 74, e : 0.35\n",
      "episode : 213/1000, score : 132, e : 0.35\n",
      "episode : 214/1000, score : 63, e : 0.34\n",
      "episode : 215/1000, score : 78, e : 0.34\n",
      "episode : 216/1000, score : 82, e : 0.34\n",
      "episode : 217/1000, score : 46, e : 0.34\n",
      "episode : 218/1000, score : 50, e : 0.34\n",
      "episode : 219/1000, score : 109, e : 0.34\n",
      "episode : 220/1000, score : 44, e : 0.33\n",
      "episode : 221/1000, score : 81, e : 0.33\n",
      "episode : 222/1000, score : 91, e : 0.33\n",
      "episode : 223/1000, score : 79, e : 0.33\n",
      "episode : 224/1000, score : 153, e : 0.33\n",
      "episode : 225/1000, score : 103, e : 0.33\n",
      "episode : 226/1000, score : 200, e : 0.32\n",
      "episode : 227/1000, score : 200, e : 0.32\n",
      "episode : 228/1000, score : 200, e : 0.32\n",
      "episode : 229/1000, score : 154, e : 0.32\n",
      "episode : 230/1000, score : 200, e : 0.32\n",
      "episode : 231/1000, score : 200, e : 0.32\n",
      "episode : 232/1000, score : 200, e : 0.31\n",
      "episode : 233/1000, score : 134, e : 0.31\n",
      "episode : 234/1000, score : 168, e : 0.31\n",
      "episode : 235/1000, score : 200, e : 0.31\n",
      "episode : 236/1000, score : 200, e : 0.31\n",
      "episode : 237/1000, score : 200, e : 0.31\n",
      "episode : 238/1000, score : 148, e : 0.3\n",
      "episode : 239/1000, score : 153, e : 0.3\n",
      "episode : 240/1000, score : 128, e : 0.3\n",
      "episode : 241/1000, score : 90, e : 0.3\n",
      "episode : 242/1000, score : 200, e : 0.3\n",
      "episode : 243/1000, score : 182, e : 0.3\n",
      "episode : 244/1000, score : 190, e : 0.3\n",
      "episode : 245/1000, score : 137, e : 0.29\n",
      "episode : 246/1000, score : 200, e : 0.29\n",
      "episode : 247/1000, score : 151, e : 0.29\n",
      "episode : 248/1000, score : 163, e : 0.29\n",
      "episode : 249/1000, score : 88, e : 0.29\n",
      "episode : 250/1000, score : 200, e : 0.29\n",
      "episode : 251/1000, score : 128, e : 0.29\n",
      "episode : 252/1000, score : 139, e : 0.28\n",
      "episode : 253/1000, score : 79, e : 0.28\n",
      "episode : 254/1000, score : 200, e : 0.28\n",
      "episode : 255/1000, score : 40, e : 0.28\n",
      "episode : 256/1000, score : 193, e : 0.28\n",
      "episode : 257/1000, score : 146, e : 0.28\n",
      "episode : 258/1000, score : 98, e : 0.28\n",
      "episode : 259/1000, score : 39, e : 0.27\n",
      "episode : 260/1000, score : 200, e : 0.27\n",
      "episode : 261/1000, score : 200, e : 0.27\n",
      "episode : 262/1000, score : 156, e : 0.27\n",
      "episode : 263/1000, score : 111, e : 0.27\n",
      "episode : 264/1000, score : 183, e : 0.27\n",
      "episode : 265/1000, score : 200, e : 0.27\n",
      "episode : 266/1000, score : 200, e : 0.26\n",
      "episode : 267/1000, score : 180, e : 0.26\n",
      "episode : 268/1000, score : 22, e : 0.26\n",
      "episode : 269/1000, score : 21, e : 0.26\n",
      "episode : 270/1000, score : 91, e : 0.26\n",
      "episode : 271/1000, score : 62, e : 0.26\n",
      "episode : 272/1000, score : 65, e : 0.26\n",
      "episode : 273/1000, score : 23, e : 0.26\n",
      "episode : 274/1000, score : 81, e : 0.25\n",
      "episode : 275/1000, score : 113, e : 0.25\n",
      "episode : 276/1000, score : 113, e : 0.25\n",
      "episode : 277/1000, score : 63, e : 0.25\n",
      "episode : 278/1000, score : 109, e : 0.25\n",
      "episode : 279/1000, score : 108, e : 0.25\n",
      "episode : 280/1000, score : 100, e : 0.25\n",
      "episode : 281/1000, score : 125, e : 0.25\n",
      "episode : 282/1000, score : 148, e : 0.24\n",
      "episode : 283/1000, score : 200, e : 0.24\n",
      "episode : 284/1000, score : 168, e : 0.24\n",
      "episode : 285/1000, score : 105, e : 0.24\n",
      "episode : 286/1000, score : 132, e : 0.24\n",
      "episode : 287/1000, score : 104, e : 0.24\n",
      "episode : 288/1000, score : 79, e : 0.24\n",
      "episode : 289/1000, score : 79, e : 0.24\n",
      "episode : 290/1000, score : 174, e : 0.23\n",
      "episode : 291/1000, score : 200, e : 0.23\n",
      "episode : 292/1000, score : 44, e : 0.23\n",
      "episode : 293/1000, score : 115, e : 0.23\n",
      "episode : 294/1000, score : 96, e : 0.23\n",
      "episode : 295/1000, score : 200, e : 0.23\n",
      "episode : 296/1000, score : 200, e : 0.23\n",
      "episode : 297/1000, score : 200, e : 0.23\n",
      "episode : 298/1000, score : 200, e : 0.23\n",
      "episode : 299/1000, score : 70, e : 0.22\n",
      "episode : 300/1000, score : 131, e : 0.22\n",
      "episode : 301/1000, score : 200, e : 0.22\n",
      "episode : 302/1000, score : 200, e : 0.22\n",
      "episode : 303/1000, score : 122, e : 0.22\n",
      "episode : 304/1000, score : 105, e : 0.22\n",
      "episode : 305/1000, score : 200, e : 0.22\n",
      "episode : 306/1000, score : 150, e : 0.22\n",
      "episode : 307/1000, score : 200, e : 0.22\n",
      "episode : 308/1000, score : 200, e : 0.21\n",
      "episode : 309/1000, score : 143, e : 0.21\n",
      "episode : 310/1000, score : 200, e : 0.21\n",
      "episode : 311/1000, score : 163, e : 0.21\n",
      "episode : 312/1000, score : 200, e : 0.21\n",
      "episode : 313/1000, score : 200, e : 0.21\n",
      "episode : 314/1000, score : 200, e : 0.21\n",
      "episode : 315/1000, score : 200, e : 0.21\n",
      "episode : 316/1000, score : 32, e : 0.21\n",
      "episode : 317/1000, score : 156, e : 0.21\n",
      "episode : 318/1000, score : 122, e : 0.2\n",
      "episode : 319/1000, score : 143, e : 0.2\n",
      "episode : 320/1000, score : 124, e : 0.2\n",
      "episode : 321/1000, score : 198, e : 0.2\n",
      "episode : 322/1000, score : 137, e : 0.2\n",
      "episode : 323/1000, score : 200, e : 0.2\n",
      "episode : 324/1000, score : 149, e : 0.2\n",
      "episode : 325/1000, score : 129, e : 0.2\n",
      "episode : 326/1000, score : 196, e : 0.2\n",
      "episode : 327/1000, score : 200, e : 0.2\n",
      "episode : 328/1000, score : 142, e : 0.19\n",
      "episode : 329/1000, score : 190, e : 0.19\n",
      "episode : 330/1000, score : 178, e : 0.19\n",
      "episode : 331/1000, score : 157, e : 0.19\n",
      "episode : 332/1000, score : 200, e : 0.19\n",
      "episode : 333/1000, score : 200, e : 0.19\n",
      "episode : 334/1000, score : 186, e : 0.19\n",
      "episode : 335/1000, score : 200, e : 0.19\n",
      "episode : 336/1000, score : 200, e : 0.19\n",
      "episode : 337/1000, score : 182, e : 0.19\n",
      "episode : 338/1000, score : 200, e : 0.18\n",
      "episode : 339/1000, score : 192, e : 0.18\n",
      "episode : 340/1000, score : 196, e : 0.18\n",
      "episode : 341/1000, score : 200, e : 0.18\n",
      "episode : 342/1000, score : 200, e : 0.18\n",
      "episode : 343/1000, score : 195, e : 0.18\n",
      "episode : 344/1000, score : 200, e : 0.18\n",
      "episode : 345/1000, score : 200, e : 0.18\n",
      "episode : 346/1000, score : 200, e : 0.18\n",
      "episode : 347/1000, score : 200, e : 0.18\n"
     ]
    }
   ],
   "source": [
    "#sort of main, to define as a class \"controller\"\n",
    "\n",
    "!python -m wandb login 46004e4ab31134349e71ceede20423c7cfdbb092\n",
    "wandb.init(project=\"RL_PLAY\", entity=\"devantheryl\")\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "batch_size = 30\n",
    "n_episode = 1000\n",
    "output_dir = 'model_output/cartepole'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "for e in range(n_episode):\n",
    "    \n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1,state_size])\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        score+=1\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1,state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(\"episode : {}/{}, score : {}, e : {:.2}\".format(e, n_episode, score, agent.epsilon))\n",
    "            agent.alighn_target_model()\n",
    "            break\n",
    "    \n",
    "    \n",
    "    if len(agent.memory) > batch_size:\n",
    "            \n",
    "            \n",
    "            agent.replay(batch_size)\n",
    "            \n",
    "\n",
    "    if e%50 == 0:\n",
    "        #agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")\n",
    "        pass\n",
    "\n",
    "env.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([[1,1,1,1]])\n",
    "\n",
    "x = np.ndarray((0,4))\n",
    "\n",
    "x = np.vstack((x, state))\n",
    "x = np.vstack((x, state))\n",
    "x = np.vstack((x, state))\n",
    "x = np.vstack((x, state))\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
